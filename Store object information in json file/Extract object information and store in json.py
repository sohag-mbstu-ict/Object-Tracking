# -*- coding: utf-8 -*-
"""batch_inference_tinydb.ipynb
​
Automatically generated by Colaboratory.
​
Original file is located at
    https://colab.research.google.com/drive/12jAHXlPz0zb-angK5POS9-1UGENqbMIh
"""
​
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount("/Test_35_points")
​
import json
​
!pip install -U ultralytics
​
import sys
import cv2
import numpy as np
import os
from ultralytics import YOLO
# model = YOLO('https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt')
model=YOLO('yolov8x.pt')
​
def detect_persons_batch_16(frame,batch_c,img_range,fr):
  # frame = torch.as_tensor(frame)
  # results =   model.predict(source=frame,  save=True, boxes=True, conf=0.3, iou=0.85,verbose=False)[0]
  predictions = model(frame, classes=0)
  # Prepare JSON output
  dt_total_list = []
  for prediction in predictions:
    dt_dict = prediction.speed
    dt = []
    for key, value in dt_dict.items():
        dt.append(value)
    dt_total = sum(dt)
    dt_total_list.append(dt_total)
​
  inference_times = np.array(dt_total_list)
  inference_times =np.mean(inference_times)
  inference_times=round(inference_times, 2)
​
  print(f"detect_persons_batch_16 Average Inference Speed: : ",inference_times)
  index_=f"batch_16_Index_{batch_c}"
  detections = []
  for box in predictions[0].boxes:
    # if box.data.name == "person":  # Assuming "person" is class 0 in your model
      detections.append({
        "fr":fr,
        "bbox": [
          int(box.xyxy[0][0]),
          int(box.xyxy[0][1]),
          int(box.xyxy[0][2]),
          int(box.xyxy[0][3]),
      ],
        "confidence": round(float(box.conf[0]),4),
        "inference_times": inference_times
      })
  # print(detections)
  return {"Batch_16": detections}
​
def detect_persons_without_batch(imgs,batch_c,img_range,fr):
  dt_total_list = []
  for img in imgs:
    predictions = model.predict(source=img,classes=0)
​
    for prediction in predictions:
      dt_dict = prediction.speed
      dt = []
      for key, value in dt_dict.items():
        dt.append(value)
      dt_total = sum(dt)
      dt_total_list.append(dt_total)
  inference_times = np.array(dt_total_list)
  inference_times =np.mean(inference_times)
  inference_times=round(inference_times, 2)
  index_=f"Without_batch_Index_{batch_c}"
  detections = []
  for box in predictions[0].boxes:
    # if box.data.name == "person":  # Assuming "person" is class 0 in your model
      detections.append({
        "fr":fr,
        "bbox": [
          int(box.xyxy[0][0]),
          int(box.xyxy[0][1]),
          int(box.xyxy[0][2]),
          int(box.xyxy[0][3]),
      ],
        "confidence": round(float(box.conf[0]),4),
        "inference_times": inference_times
      })
  print(f"detect_persons_without_batch Average Inference Speed: : ",inference_times)
  return {"Without_batch": detections}
​
​
​
conf_thresh = 0.5
# Output file for results (optional)
result_file = "detections32.json"
# with open(result_file, "w") as f:
#   json.dump('', f)
# Open video capture (can be webcam or video file)
cap = cv2.VideoCapture("/Test_35_points/MyDrive/YOLOv8_Train_35Keypoints/video/trimed_3.mkv")
model=YOLO('yolov8x.pt')
fr =0
# Loop through each frame
batch_size=32
img_list=[]
img_range=[]
batch_c=0
while True:
  # Read frame
  ret, frame = cap.read()
  fr+=1
  if not ret:
    print("fr : ",fr)
    break
  img_list.append(frame)
  img_range.append(fr)
  if(len(img_list)==batch_size):
    batch_c+=1
    print("fr : ",fr)
    # Run person detection with batch = 16
    detections = detect_persons_batch_16(img_list,batch_c,img_range,fr)
    if result_file:
      with open(result_file, "a") as f:
        json.dump(detections, f)
​
    # Run person detection without batch
    detections = detect_persons_without_batch(img_list,batch_c,img_range,fr)
    if result_file:
      with open(result_file, "a") as f:
        json.dump(detections, f)
    img_range=[]
    img_list=[]
    # break
    if(fr>1500):
      break
​
cap.release()
cv2.destroyAllWindows()